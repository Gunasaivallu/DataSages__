---
title: AI Data Analyst Agent
emoji: ğŸ“Š
colorFrom: indigo
colorTo: blue
sdk: docker
app_port: 7860
pinned: false
---





# ğŸ“Š AI Data Analyst Agent for CSV-Based Analysis

**Employee Name:** Gunasaivallu

---

## 1. Research Question / Hypothesis

Can a **Plannerâ€“Validatorâ€“Executorâ€“Explainer architecture**, powered by Large Language Models (LLMs), enable **safe, reproducible, and structured analysis of CSV datasets**, while preventing hallucinated computations and non-deterministic execution commonly observed in end-to-end LLM data analysis systems?

---

## 2. Motivation and Relevance

Large Language Models are increasingly used for data analysis tasks. However, many existing systems:

- Hallucinate numerical results  
- Generate unverifiable reasoning steps  
- Directly execute LLM-generated code on user data  
- Produce non-reproducible outputs  

These issues pose significant risks in analytical and decision-making contexts.

This project addresses these challenges by enforcing a **strict separation between reasoning and execution**, ensuring that:

- LLMs are used **only for planning and explanation**
- All numerical computations are performed **deterministically using pandas**
- Every analytical step is **validated before execution**

This design significantly improves **trustworthiness, safety, and reproducibility**.

---

## 3. System Architecture

The system is implemented as a **two-tier architecture** consisting of a Streamlit frontend and a FastAPI backend, connected via a REST API.

### Architectural Flow
```
  User (Streamlit UI)
          â†“
FastAPI Backend (`/analyze`)
          â†“
  Planner Agent (LLM)
          â†“
Plan Validator (Schema Enforcement)
          â†“
Executor (Deterministic pandas Execution)
          â†“
  Explainer Agent (LLM)
          â†“
Structured Results + Natural Language Insights
          â†“
  Streamlit UI Display
```


### Key Architectural Principle

> **LLMs never perform numerical computation.**  
> All calculations are executed deterministically using pandas after schema validation.

---

## 4. Model(s) and Versions Used

- **Large Language Model:** Groq-hosted LLM  
- **Usage Scope:**
  - Planner Agent â†’ generates structured analysis plans  
  - Explainer Agent â†’ generates natural language explanations  
- **Execution Engine:** pandas (Python)  
- **Backend Framework:** FastAPI  
- **Frontend Framework:** Streamlit  

The executor and validator layers are entirely **LLM-independent**.

---

## 5. Prompting and/or Fine-Tuning Strategy

### Prompting Strategy

#### Planner Agent
- Receives dataset column names and the user question  
- Produces a structured, machine-readable analysis plan (JSON)  
- Explicitly constrained to allowed operations  

#### Explainer Agent
- Receives execution results and the validated plan  
- Generates descriptive, human-readable insights  
- **Forbidden from generating numerical values**

### Fine-Tuning

- No fine-tuning was performed  
- The system relies on **prompt constraints and architectural enforcement** rather than model retraining

---

## 6. Evaluation Protocol

The system was evaluated using multiple CSV datasets and analytical queries, focusing on:

- Numerical correctness of results  
- Absence of hallucinated values  
- Schema validation effectiveness  
- Reproducibility across repeated runs  
- Explainability of outputs  

Dataset overview queries (e.g., *â€œDescribe the datasetâ€*) were evaluated separately to ensure correct routing without invoking the plannerâ€“executor pipeline.

---

## 7. Key Results

- âœ… Zero hallucinated numerical outputs  
- âœ… Fully deterministic and reproducible execution  
- âœ… Clear reasoning trace via structured analysis plans  
- âœ… Safe handling of arbitrary CSV files  
- âœ… Improved interpretability through explicit explanations  

*(Results are derived from system execution logs and evaluation notebooks in the `notebooks/` directory.)*

---

## 8. Known Limitations and Ethical Considerations

### Known Limitations
- Supports only CSV file format  
- Single-table analysis only  
- In-memory execution limits scalability for very large datasets  
- Limited visualization support (tabular outputs only)  

### Ethical Considerations
- No training or storage of user data  
- No external data sources accessed  
- Deterministic execution prevents misleading or fabricated results  
- User datasets remain session-scoped  

---

## 9. Exact Instructions to Reproduce Results

### 1ï¸âƒ£ Environment Setup

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```
### 2ï¸âƒ£ Environment Variables

Create a `.env` file using `.env.example`:

```env
GROQ_API_KEY=your_api_key_here
```

### 3ï¸âƒ£ Start Backend (FastAPI)

```bash
uvicorn src.main:app --host 0.0.0.0 --port 8000
```

### 4ï¸âƒ£ Start Frontend (Streamlit)

```bash
streamlit run frontend/app.py
```

### 5ï¸âƒ£ Usage

- Upload a CSV file  
- Ask a natural language analytical question  
- View:
  - Generated analysis plan  
  - Deterministic results  
  - Natural language explanation  

### 6ï¸âƒ£ Optional: Docker

```bash
docker build -t ai-data-analyst .
docker run -p 8000:8000 ai-data-analyst
```

## Appendix A: Project Structure

```text
Datasages/
â”‚
â”œâ”€â”€ data/                       # Sample CSV datasets
â”‚   â”œâ”€â”€ Book1.csv
â”‚   â””â”€â”€ population_by_country_2020.csv
â”‚
â”œâ”€â”€ experiments/                # Experiment configurations
â”‚   â”œâ”€â”€ exp_01.yaml
â”‚   â””â”€â”€ exp_02.yaml
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app.py                  # Streamlit UI
â”‚
â”œâ”€â”€ notebooks/                  # Exploration & evaluation notebooks
â”‚   â”œâ”€â”€ 01_exploration.ipynb
â”‚   â””â”€â”€ 02_evaluation.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ planner.py          # LLM-based planner
â”‚   â”‚   â”œâ”€â”€ explainer.py        # LLM-based explainer
â”‚   â”‚   â””â”€â”€ dataset_analyzer.py # Dataset summary logic
â”‚   â”‚
â”‚   â”œâ”€â”€ executor/
â”‚   â”‚   â””â”€â”€ executor.py         # Deterministic pandas execution
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ plan_validator.py   # Plan validation rules
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py               # Model & environment config
â”‚   â””â”€â”€ main.py                 # FastAPI backend entry point
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ project.yaml
â”œâ”€â”€ reproducibility.md
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

```
